# Robots.txt for Payload CMS Blog
# Google Search crawlers ARE ALLOWED - only blocking admin/API paths

User-agent: *
# Allow all public content pages
Allow: /

# Block admin and API paths (these shouldn't be indexed anyway)
Disallow: /admin
Disallow: /api/
Disallow: /my-route

# Block common attack vectors
Disallow: /wp-admin
Disallow: /wp-login
Disallow: /.env
Disallow: /xmlrpc.php

# Sitemap (when you add one)
# Sitemap: https://your-domain.com/sitemap.xml

# Block AI training bots (NOT search crawlers)
# These bots scrape content for AI training, not search indexing
User-agent: GPTBot
Disallow: /

User-agent: ChatGPT-User
Disallow: /

User-agent: CCBot
Disallow: /

User-agent: anthropic-ai
Disallow: /

User-agent: Claude-Web
Disallow: /

User-agent: Google-Extended
Disallow: /

User-agent: FacebookBot
Disallow: /

# Note: Googlebot, Bingbot, and other search crawlers ARE ALLOWED
# Only AI training bots and admin paths are blocked
